{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrhJGeeVvFBnnb96OEjW48",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aya11ali/Shouf/blob/main/Video_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0X9fOSPFHQ4g"
      },
      "outputs": [],
      "source": [
        "!pip install -q moviepy faster-whisper langdetect\n",
        "!pip install -q transformers einops accelerate langchain bitsandbytes sentencepiece langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "from abc import ABC, abstractmethod\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "from langdetect import detect, DetectorFactory\n",
        "from langdetect.lang_detect_exception import LangDetectException\n",
        "\n",
        "from langchain import HuggingFacePipeline, PromptTemplate, LLMChain\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "import transformers\n",
        "import torch\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ],
      "metadata": {
        "id": "FaP92GLwHTgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "XWk4nQbsHUqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Y90xCke9HV5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioExtractionError(Exception):\n",
        "    \"\"\"Custom exception for audio extraction errors.\"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "OB-uMc8vHYxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IAudioExtraction(ABC):\n",
        "  @abstractmethod\n",
        "  def __init__(self,video_path:str , audio_path:str = 'extracted_audio.mp3'):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def check_video_path(self)-> None:\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def extract_audio(self) -> None:\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def check_audio_validation(self)-> bool:\n",
        "    pass\n",
        "\n",
        "class AudioExtraction(IAudioExtraction):\n",
        "  def __init__(self,video_path:str , audio_path:str = 'extracted_audio.mp3'):\n",
        "    self.video_path = video_path\n",
        "    self.audio_path = audio_path\n",
        "    self.result = None\n",
        "    self.extract_audio()\n",
        "\n",
        "  def check_video_path(self) -> None:\n",
        "    if not os.path.exists(self.video_path):\n",
        "      raise ValueError(f\"Video path {self.video_path} does not exist\")\n",
        "\n",
        "  def extract_audio(self) -> None:\n",
        "    self.check_video_path()\n",
        "    command = [\n",
        "          \"ffmpeg\",\n",
        "          \"-y\",\n",
        "          \"-i\", self.video_path,\n",
        "          \"-vn\",\n",
        "          \"-acodec\", \"libmp3lame\",\n",
        "          self.audio_path\n",
        "      ]\n",
        "\n",
        "    self.result = subprocess.run(command, stdout=subprocess.PIPE,\n",
        "                              stderr=subprocess.PIPE, text=True)\n",
        "    self.check_audio_validation()\n",
        "\n",
        "\n",
        "  def check_audio_validation(self) -> bool:\n",
        "      if self.result.returncode != 0:\n",
        "          raise AudioExtractionError(f\"Failed to extract audio from video. Error: {self.result.stderr}\")\n",
        "\n",
        "      logging.info(\"Audio extracted successfully\")\n",
        "      return True"
      ],
      "metadata": {
        "id": "B_0Bo0TvHaLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IAudio_Model_Loader (ABC):\n",
        "  @abstractmethod\n",
        "  def __init__ (self,model_size=\"medium\",compute_type=\"int8\"):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def load_model (self):\n",
        "    pass\n",
        "\n",
        "class Audio_Model_Loader (IAudio_Model_Loader):\n",
        "  def __init__ (self,model_size=\"medium\",compute_type=\"int8\"):\n",
        "    self.model_size = model_size\n",
        "    self.compute_type = compute_type\n",
        "    self.model = None\n",
        "    self.load_model()\n",
        "\n",
        "  def load_model (self):\n",
        "    self.model = WhisperModel(self.model_size, compute_type=self.compute_type)"
      ],
      "metadata": {
        "id": "62krSKPBHcZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IAudio_Transcriber(ABC):\n",
        "  @abstractmethod\n",
        "  def __init__ (self,audio_path):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def transcribe_audio(self):\n",
        "    pass\n",
        "\n",
        "class Audio_Transcriber(IAudio_Transcriber):\n",
        "  def __init__ (self,audio_path,model):\n",
        "    self.audio_path = audio_path\n",
        "    self.segments = None\n",
        "    self.model = model\n",
        "    self.transcription=\"\"\n",
        "    self.transcribe_audio()\n",
        "\n",
        "  def transcribe_audio(self):\n",
        "    self.segments, _ = self.model.transcribe(self.audio_path, beam_size=5)\n",
        "\n",
        "    for segment in self.segments:\n",
        "        self.transcription += segment.text.strip() + \" \"\n",
        "\n",
        "    self.transcription = self.transcription.strip()"
      ],
      "metadata": {
        "id": "KBhDCsqgHecZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DetectorFactory.seed = 0\n",
        "\n",
        "class IDetectLanguage(ABC):\n",
        "  @abstractmethod\n",
        "  def detect_language(self,text:str)-> str:\n",
        "    pass\n",
        "\n",
        "class DetectLanguage(IDetectLanguage):\n",
        "  def detect_language(self,text:str)-> str:\n",
        "    try:\n",
        "\n",
        "      return detect(text)\n",
        "    except LangDetectException:\n",
        "      return \"Unknown\""
      ],
      "metadata": {
        "id": "MSPJRxGnHgE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoToTextController(ABC):\n",
        "  def __init__ (self, video_path : str , audio_path : str = 'extracted_audio.mp3'):\n",
        "    self.video_path = video_path\n",
        "    self.audio_path = audio_path\n",
        "\n",
        "    self.audio_extraction = AudioExtraction(self.video_path,self.audio_path)\n",
        "    self.audio_model_loader = Audio_Model_Loader()\n",
        "\n",
        "    self.audio_transcriber = Audio_Transcriber(self.audio_path,self.audio_model_loader.model)"
      ],
      "metadata": {
        "id": "27y77cmWHhKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  videoText = VideoToTextController(\"/content/22.mp4\")\n",
        "  print(videoText.audio_transcriber.transcription)"
      ],
      "metadata": {
        "id": "GhZUpJosHjZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ],
      "metadata": {
        "id": "tzWYi5ecHlxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ISummarizer(ABC):\n",
        "    @abstractmethod\n",
        "    def __init__(self, text: str):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def summarize_text(self) -> str:\n",
        "        pass\n",
        "\n",
        "\n",
        "class Summarizer(ISummarizer):\n",
        "    def __init__(self, text: str, model: str = \"meta-llama/Llama-2-7b-chat-hf\"):\n",
        "        self.text = text\n",
        "        self.model = model\n",
        "\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "            self.pipeline = pipeline(\n",
        "                \"text-generation\",\n",
        "                model=self.model,\n",
        "                tokenizer=self.tokenizer,\n",
        "                torch_dtype=torch.float16,\n",
        "                device=0,\n",
        "                trust_remote_code=True,\n",
        "                max_length=512,\n",
        "                do_sample=True,\n",
        "                top_k=10,\n",
        "                num_return_sequences=1,\n",
        "                eos_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "            self.template = \"\"\"\n",
        "                              You are a helpful summarization assistant.\n",
        "\n",
        "                              Write a clear and concise **paragraph summary** of the following text, delimited by triple backticks.\n",
        "                              The summary should capture the **main ideas** and **important details** without exceeding **300 words**.\n",
        "\n",
        "                              ```{text}```\n",
        "\n",
        "                              PARAGRAPH SUMMARY (max 300 words):\n",
        "                          \"\"\"\n",
        "            prompt = PromptTemplate(template=self.template, input_variables=[\"text\"])\n",
        "            llm = HuggingFacePipeline(pipeline=self.pipeline)\n",
        "            self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to initialize model or tokenizer: {e}\")\n",
        "\n",
        "    def summarize_text(self) -> str:\n",
        "        try:\n",
        "            # Use LLMChain to generate the summary\n",
        "            summary = self.llm_chain.run({\"text\": self.text})\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to summarize text: {e}\")\n"
      ],
      "metadata": {
        "id": "sQjEJ6TrHnwb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}